# P2P-LLM-Forge

[![Python](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.8+-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

P2P-LLM-Forge, PyTorch DistributedDataParallel (DDP) kullanarak peer-to-peer kÃ¼me ortamÄ±nda nedensel dil modellerinin (causal language models) veri-paralel eÄŸitimini gerÃ§ekleÅŸtiren bir MVP (Minimum Viable Product) projesidir.

Bu proje, modern daÄŸÄ±tÄ±lmÄ±ÅŸ makine Ã¶ÄŸrenmesi uygulamalarÄ±nda karÅŸÄ±laÅŸÄ±lan zorluklarÄ± ele alÄ±r ve araÅŸtÄ±rmacÄ±lar ile geliÅŸtiricilerin Ã§ok dÃ¼ÄŸÃ¼mlÃ¼ eÄŸitim ortamlarÄ±nÄ± test etmelerine olanak saÄŸlar.

## âœ¨ Ã–zellikler

- **Merkezi KonfigÃ¼rasyon**: Hiperparametreler ve daÄŸÄ±tÄ±lmÄ±ÅŸ Ã§alÄ±ÅŸma zamanÄ± ayarlarÄ± iÃ§in merkezi konfigÃ¼rasyon sistemi
- **Otomatik SÃ¼reÃ§ Grubu YÃ¶netimi**: PyTorch DDP iÃ§in otomatik sÃ¼reÃ§ grubu kurulumu ve kapatÄ±lmasÄ±
- **AkÄ±llÄ± Veri Ä°ÅŸleme**: Metin korpuslarÄ± iÃ§in tokenization ve paylaÅŸÄ±lan depolama Ã¼zerinde shard edilmiÅŸ veri yÃ¼kleme
- **GeliÅŸmiÅŸ EÄŸitim DÃ¶ngÃ¼sÃ¼**: Gradyan senkronizasyonu, isteÄŸe baÄŸlÄ± gradyan kÄ±rpma ve rank 0'dan checkpoint'leme
- **Esnek DaÄŸÄ±tÄ±m**: Tek makine ve Ã§ok dÃ¼ÄŸÃ¼mlÃ¼ daÄŸÄ±tÄ±lmÄ±ÅŸ eÄŸitim desteÄŸi
- **CPU/GPU UyumluluÄŸu**: Hem CPU hem GPU ortamlarÄ±nda Ã§alÄ±ÅŸabilme

## ğŸ“‹ Gereksinimler

- **Python**: 3.10 veya Ã¼zeri
- **PyTorch**: 2.8+
- **CUDA**: GPU eÄŸitimi iÃ§in (isteÄŸe baÄŸlÄ±)
- **uv**: Modern Python paket yÃ¶neticisi

## ğŸš€ Kurulum

### 1. Depoyu KlonlayÄ±n
```bash
git clone <repository-url>
cd p2p-llm-forge
```

### 2. BaÄŸÄ±mlÄ±lÄ±klarÄ± YÃ¼kleyin
```bash
uv sync
```

Bu komut tÃ¼m gerekli baÄŸÄ±mlÄ±lÄ±klarÄ± (PyTorch, Transformers, tqdm) yÃ¼kleyecektir.

## ğŸ“– KullanÄ±m

### Tek Makine Testi

Proje ile birlikte gelen Ã¶rnek veri seti ile hÄ±zlÄ± bir test Ã§alÄ±ÅŸtÄ±rmak iÃ§in:

```bash
uv run python tests/smoke_single_node.py
```

Bu komut:
- KÃ¼Ã§Ã¼k `sshleifer/tiny-gpt2` modelini indirir
- `data/sample_corpus.txt` dosyasÄ±ndaki Ã¶rnek veriyi kullanÄ±r
- CPU dostu `gloo` backend ile 1 epoch eÄŸitim gerÃ§ekleÅŸtirir
- SonuÃ§larÄ± `artifacts/smoke/` klasÃ¶rÃ¼ne kaydeder

### DaÄŸÄ±tÄ±lmÄ±ÅŸ EÄŸitim

Ã‡ok dÃ¼ÄŸÃ¼mlÃ¼ eÄŸitim iÃ§in her dÃ¼ÄŸÃ¼mde aÅŸaÄŸÄ±daki komutu Ã§alÄ±ÅŸtÄ±rÄ±n:

```bash
# Temel kullanÄ±m
uv run p2p-llm-forge \
  --model-name gpt2 \
  --dataset-path /path/to/dataset.txt \
  --output-dir ./artifacts \
  --epochs 1 \
  --batch-size 2 \
  --sequence-length 128

# torchrun ile Ã§ok dÃ¼ÄŸÃ¼mlÃ¼ eÄŸitim
torchrun --nnodes=2 --nproc_per_node=1 \
  --master_addr=node1 --master_port=29500 \
  uv run p2p-llm-forge \
  --model-name gpt2 \
  --dataset-path /path/to/dataset.txt \
  --output-dir ./artifacts \
  --epochs 10 \
  --batch-size 4 \
  --sequence-length 512 \
  --backend nccl
```

### Komut SatÄ±rÄ± SeÃ§enekleri

TÃ¼m kullanÄ±labilir seÃ§enekleri gÃ¶rmek iÃ§in:

```bash
uv run p2p-llm-forge --help
```

**Ã–nemli Parametreler:**
- `--model-name`: HuggingFace model tanÄ±mlayÄ±cÄ±sÄ±
- `--dataset-path`: EÄŸitim veri seti yolu
- `--output-dir`: Checkpoint'lerin kaydedileceÄŸi dizin
- `--epochs`: EÄŸitim epoch sayÄ±sÄ±
- `--batch-size`: KÃ¼resel batch boyutu
- `--sequence-length`: Token baÅŸÄ±na maksimum sekans uzunluÄŸu
- `--backend`: DaÄŸÄ±tÄ±lmÄ±ÅŸ backend (`nccl` veya `gloo`)
- `--master-addr/--master-port`: Ana dÃ¼ÄŸÃ¼m baÄŸlantÄ± bilgileri

## ğŸ—ï¸ Proje YapÄ±sÄ±

```
p2p-llm-forge/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ p2p_llm_forge/
â”‚       â”œâ”€â”€ __init__.py          # Paket baÅŸlatma
â”‚       â”œâ”€â”€ __main__.py          # CLI giriÅŸ noktasÄ±
â”‚       â”œâ”€â”€ config.py            # KonfigÃ¼rasyon yÃ¶netimi
â”‚       â”œâ”€â”€ data.py              # Veri yÃ¼kleme ve iÅŸleme
â”‚       â”œâ”€â”€ distributed.py       # DaÄŸÄ±tÄ±lmÄ±ÅŸ eÄŸitim yÃ¶netimi
â”‚       â””â”€â”€ trainer.py           # EÄŸitim dÃ¶ngÃ¼sÃ¼
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample_corpus.txt        # Ã–rnek veri seti
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ smoke_single_node.py     # Tek makine test senaryosu
â”œâ”€â”€ pyproject.toml               # Proje konfigÃ¼rasyonu
â””â”€â”€ README.md                    # Bu dosya
```

### Ana ModÃ¼ller

- **`config.py`**: EÄŸitim hiperparametreleri ve daÄŸÄ±tÄ±lmÄ±ÅŸ ayarlar iÃ§in merkezi konfigÃ¼rasyon
- **`data.py`**: Tokenization ve shard edilmiÅŸ veri yÃ¼kleme iÅŸlemleri
- **`distributed.py`**: PyTorch DDP sÃ¼reÃ§ grubu yÃ¶netimi
- **`trainer.py`**: EÄŸitim dÃ¶ngÃ¼sÃ¼, kayÄ±p hesaplama ve optimizasyon

## âš™ï¸ KonfigÃ¼rasyon

Proje aÅŸaÄŸÄ±daki konfigÃ¼rasyon seÃ§eneklerini destekler:

### DaÄŸÄ±tÄ±lmÄ±ÅŸ EÄŸitim
- **Backend**: `nccl` (GPU) veya `gloo` (CPU)
- **Rank/World Size**: SÃ¼reÃ§ sÄ±ralamasÄ± ve toplam sÃ¼reÃ§ sayÄ±sÄ±
- **Master Node**: Ana koordinasyon dÃ¼ÄŸÃ¼mÃ¼ bilgileri

### Model ve Veri
- **Model**: Herhangi bir HuggingFace causal LM modeli
- **Veri**: Metin dosyasÄ± formatÄ±nda veri setleri
- **Sequence Length**: Maksimum token uzunluÄŸu

### EÄŸitim Parametreleri
- **Batch Size**: KÃ¼resel batch boyutu (tÃ¼m sÃ¼reÃ§lerde toplam)
- **Learning Rate**: Optimizasyon Ã¶ÄŸrenme oranÄ±
- **Epochs**: EÄŸitim dÃ¶nemi sayÄ±sÄ±
- **Gradient Clipping**: Gradyan kÄ±rpma eÅŸiÄŸi

### GeliÅŸtirme

```bash
# GeliÅŸtirme ortamÄ±nÄ± kurun
uv sync --editable

# Testleri Ã§alÄ±ÅŸtÄ±rÄ±n
uv run python tests/smoke_single_node.py

# Kod kalitesi kontrolÃ¼
uv run ruff check .
uv run ruff format .
```

Bu proje MIT LisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r. Detaylar iÃ§in [LICENSE](LICENSE) dosyasÄ±na bakÄ±nÄ±z.

## ğŸ“ Ä°letiÅŸim

SorularÄ±nÄ±z ve geri bildirimleriniz iÃ§in issue aÃ§maktan Ã§ekinmeyin!

---
